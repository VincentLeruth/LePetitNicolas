"""
Module d'entraÃ®nement d'un modÃ¨le Gradient Boosting pour la prÃ©diction de pays.

Ce script entraÃ®ne un modÃ¨le de classification supervisÃ©e (HistGradientBoostingClassifier)
pour prÃ©dire le pays associÃ© Ã  un document en fonction de ses vecteurs TF-IDF.

FonctionnalitÃ©s :
- Colonne cible : 'country' (France, Germany, Benelux, Others)
- Utilise un Gradient Boosting avec pondÃ©ration automatique des classes (`class_weight='balanced'`)
- Validation croisÃ©e stratifiÃ©e conditionnelle selon la taille minimale des classes
- Sauvegarde automatique du modÃ¨le et de l'encodeur de labels dans le rÃ©pertoire `models`

Fichiers utilisÃ©s :
- DonnÃ©es d'entrÃ©e : `data/processed/tfidf_vectors.csv`
- Ã‰tiquettes : `data/labeled.csv`
- ModÃ¨les sauvegardÃ©s : `models/country_gb_model.joblib` et `models/country_label_encoder.joblib`
"""

import os
import pandas as pd
import joblib
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.metrics import classification_report
from commite_github import commit_file_to_github


def train_country():
    """
    EntraÃ®ne un modÃ¨le HistGradientBoostingClassifier pour prÃ©dire le pays associÃ© Ã  un document.

    Ã‰tapes principales :
    1. Chargement des donnÃ©es TF-IDF et des labels depuis les fichiers CSV.
    2. Fusion et nettoyage des DataFrames.
    3. PrÃ©paration des features (X) et de la cible (y).
    4. Encodage des labels de pays en entiers via LabelEncoder.
    5. EntraÃ®nement dâ€™un modÃ¨le Gradient Boosting avec pondÃ©ration Ã©quilibrÃ©e des classes.
    6. Validation croisÃ©e stratifiÃ©e conditionnelle si suffisamment dâ€™Ã©chantillons.
    7. Sauvegarde du modÃ¨le entraÃ®nÃ© et de lâ€™encodeur.

    Raises
    ------
    ValueError
        Si aucune colonne de features nâ€™est trouvÃ©e ou si toutes les valeurs sont nulles.
        Si le nombre de lignes entre X et y ne correspond pas.
    """

    # --- DÃ©finition des chemins relatifs ---
    base_dir = os.path.dirname(__file__)
    path_vectors = os.path.join(base_dir, "..", "..", "..", "data", "processed", "tfidf_vectors.csv")
    path_labels = os.path.join(base_dir, "..", "..", "..", "data", "labeled.csv")
    models_dir = os.path.join(base_dir, "..", "..", "..", "models")
    os.makedirs(models_dir, exist_ok=True)

    # --- Chargement des donnÃ©es ---
    df_vectors = pd.read_csv(path_vectors, sep=";")
    df_labels = pd.read_csv(path_labels, sep=";")

    # --- Fusion sur la colonne 'doc' et suppression des lignes sans pays ---
    df = pd.merge(df_vectors, df_labels, on="doc", how="inner").dropna(subset=["country_y"])

    # Suppression de colonnes non pertinentes pour la prÃ©diction
    df = df.drop(columns=["label", "domain"], errors="ignore")

    # --- PrÃ©paration des features (X) et de la target (y) ---
    X_df = df.drop(columns=["doc", "country_y"], errors="ignore")
    X_df = pd.DataFrame(X_df)

    # VÃ©rification quâ€™il reste bien des colonnes de features
    if X_df.shape[1] == 0:
        raise ValueError("Aucune colonne de features trouvÃ©e (aprÃ¨s drop doc/country).")

    # Conversion en numÃ©rique et remplacement des NaN par 0
    X_num = X_df.apply(pd.to_numeric, errors="coerce").fillna(0)

    # VÃ©rification de la prÃ©sence de valeurs informatives
    if (X_num.abs().sum(axis=0) != 0).sum() == 0:
        raise ValueError("Toutes les features sont nulles â€” vÃ©rifie tfidf_vectors.csv.")

    # --- PrÃ©paration de la variable cible ---
    y_raw = df["country_y"].astype(str)

    # VÃ©rification de la cohÃ©rence X/y
    if X_num.shape[0] != len(y_raw):
        raise ValueError(f"IncohÃ©rence X/y: X.shape[0]={X_num.shape[0]} vs len(y)={len(y_raw)}")

    # --- Encodage des labels de pays ---
    le = LabelEncoder()
    y = le.fit_transform(y_raw)

    # --- DÃ©finition du modÃ¨le Gradient Boosting ---
    model = HistGradientBoostingClassifier(
        max_iter=200,
        random_state=42,
        class_weight='balanced'
    )

    # --- DÃ©termination dynamique du nombre de splits pour la validation croisÃ©e ---
    series_counts = pd.Series(y).value_counts()
    n_min = int(series_counts.min()) if not series_counts.empty else 0
    n_splits = min(3, n_min) if n_min >= 2 else 0

    # --- Validation croisÃ©e stratifiÃ©e conditionnelle ---
    if n_splits >= 2:
        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
        try:
            y_pred = cross_val_predict(model, X_num, y, cv=cv)
            print("Classification report (cross-validation) :")
            print(classification_report(y, y_pred, target_names=le.classes_, zero_division=0))
        except Exception as e:
            print(f"cross_val_predict a Ã©chouÃ© ({type(e).__name__}): {e}")
            print("â†’ On passera directement Ã  l'entraÃ®nement final sans CV.")
    else:
        print("Cross-validation skipped: pas assez d'exemples par classe pour n_splits>=2.")

    # --- EntraÃ®nement final sur l'ensemble du jeu de donnÃ©es ---
    model.fit(X_num, y)

    # --- Sauvegarde du modÃ¨le et de l'encodeur ---
    files_to_commit = [
    os.path.join(models_dir, "country_gb_model.joblib"),
    os.path.join(models_dir, "country_label_encoder.joblib")
    ]
    for file_path in files_to_commit:
        commit_file_to_github(
            local_file_path=file_path,
            repo_path=file_path,  # conserve le mÃªme chemin dans le repo
            commit_message=f"Update {os.path.basename(file_path)}"
        )
        print(f"ğŸš€ {os.path.basename(file_path)} commitÃ© sur GitHub avec succÃ¨s !")

   


# --- Point d'entrÃ©e principal ---
if __name__ == "__main__":
    train_country()
