"""
Module : predict_tech
=====================

Ce module r√©alise la **pr√©diction multi-label** des technologies d‚Äôun document
(`hard`, `soft`, ou `both`) √† partir de vecteurs TF-IDF et d‚Äôun mod√®le
de **r√©gression logistique One-vs-Rest** pr√©alablement entra√Æn√©.

Fonctionnalit√©s principales :
-----------------------------
- Chargement du mod√®le de classification multi-label (`lr_multilabel_techno_model.joblib`)
- Chargement des vecteurs TF-IDF depuis `data/processed/tfidf_vectors.csv`
- Calcul des probabilit√©s pour chaque label (`hard`, `soft`)
- Application d‚Äôun seuil de confiance (`0.5` par d√©faut)
- Fusion des r√©sultats pour produire un label combin√© :  
  `"hard"`, `"soft"`, `"both"`, ou `"unknown"`
- Export des r√©sultats dans un CSV contenant :  
  `doc`, `predicted_tech`, et `confidence_score`

Fichier de sortie :
-------------------
- `output/predictions/tfidf_vectors_with_tech_predictions.csv`

Auteur :
--------
Fait partie du pipeline de pr√©diction documentaire multi-label.
"""

import os
import pandas as pd
import joblib
import numpy as np

from commite_github import commit_file_to_github

def predict_tech():
    """
    Effectue les pr√©dictions de labels 'hard' et 'soft' sur un jeu de vecteurs TF-IDF.

    Description d√©taill√©e
    ----------------------
    1. Charge le mod√®le de r√©gression logistique multi-label (One-vs-Rest)
    2. Charge les vecteurs TF-IDF et v√©rifie que toutes les features du mod√®le sont pr√©sentes
    3. Calcule les probabilit√©s de chaque label pour chaque document
    4. Applique un seuil de confiance (0.5) pour d√©terminer la pr√©sence du label
    5. Fusionne les deux sorties (`hard` / `soft`) en un label combin√© (`both`, `hard`, `soft`, `unknown`)
    6. Sauvegarde les r√©sultats avec le score de confiance global

    Notes
    -----
    - Le mod√®le doit avoir √©t√© entra√Æn√© et sauvegard√© au pr√©alable via `train_tech.py`.
    - Le seuil de pr√©diction est configurable via la variable `threshold`.
    - Si une feature attendue par le mod√®le est absente du CSV, elle est ajout√©e et remplie par des z√©ros.
    - La confiance globale est le **maximum** entre la proba 'hard' et la proba 'soft'.

    Returns
    -------
    None
        Les pr√©dictions sont sauvegard√©es dans un fichier CSV √† la fin de l‚Äôex√©cution.
    """

    # --- Seuil de probabilit√© pour consid√©rer un label comme pr√©sent ---
    threshold = 0.5

    # --- D√©finition des chemins relatifs ---
    base_dir = os.path.dirname(__file__)
    model_path = os.path.join(base_dir, "..", "..", "..", "models", "lr_multilabel_techno_model.joblib")
    vectors_path = os.path.join(base_dir, "..", "..", "..", "data", "processed", "tfidf_vectors.csv")

    output_dir = os.path.join(base_dir, "..", "..", "..", "output", "predictions")
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, "tfidf_vectors_with_tech_predictions.csv")

    # --- Chargement du mod√®le entra√Æn√© ---
    clf = joblib.load(model_path)

    # --- Chargement des vecteurs TF-IDF complets ---
    df_vectors_full = pd.read_csv(vectors_path, sep=";")

    # --- V√©rification que toutes les features attendues par le mod√®le existent ---
    feature_names = clf.estimators_[0].feature_names_in_
    missing_feats = [feat for feat in feature_names if feat not in df_vectors_full.columns]

    # Si certaines features manquent, les ajouter avec valeur 0 (aucune occurrence)
    if missing_feats:
        zeros_df = pd.DataFrame(0, index=df_vectors_full.index, columns=missing_feats)
        df_vectors_full = pd.concat([df_vectors_full, zeros_df], axis=1)

    # --- S√©lection des colonnes correspondant aux features du mod√®le ---
    X = df_vectors_full[feature_names]

    # --- Pr√©dictions de probabilit√© pour chaque classe (hard / soft) ---
    hard_proba_all = clf.estimators_[0].predict_proba(X)
    soft_proba_all = clf.estimators_[1].predict_proba(X)

    # --- Gestion des cas o√π une seule classe est pr√©sente (1D) ---
    if hard_proba_all.shape[1] == 1:
        hard_probs = np.zeros(len(X))
    else:
        hard_probs = hard_proba_all[:, 1]

    if soft_proba_all.shape[1] == 1:
        soft_probs = np.zeros(len(X))
    else:
        soft_probs = soft_proba_all[:, 1]

    # --- Calcul du score de confiance global ---
    global_confidence = np.maximum(hard_probs, soft_probs)

    # --- Application du seuil de d√©cision ---
    hard_pred = np.where(hard_probs >= threshold, "hard", "unknown")
    soft_pred = np.where(soft_probs >= threshold, "soft", "unknown")

    # --- Fusion des deux pr√©dictions en un seul label final ---
    combined_pred = []
    for h, s in zip(hard_pred, soft_pred):
        if h == "hard" and s == "soft":
            combined_pred.append("both")
        elif h == "hard":
            combined_pred.append("hard")
        elif s == "soft":
            combined_pred.append("soft")
        else:
            combined_pred.append("unknown")

    # --- Construction du DataFrame final de r√©sultats ---
    df_results = pd.DataFrame({
        "doc": df_vectors_full["doc"],
        "predicted_tech": combined_pred,
        "confidence_score": global_confidence
    })

    # --- Sauvegarde des r√©sultats ---
    commit_file_to_github(
        local_file_path=output_file,
        repo_path=output_file,
        commit_message="Update tech prediction results"
    )
    print("üöÄ R√©sultats technologie committ√©s sur GitHub avec succ√®s !")


# --- Point d‚Äôentr√©e principal ---
if __name__ == "__main__":
    predict_tech()
